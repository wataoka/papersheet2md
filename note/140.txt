## 概要
- オートエンコーダーの潜在空間をdisentanglingし, 1つの属性だけを変化させる手法Matrix Subspace Projection (MSP)を提案.
- MSPのいいところ
  - MSPは既存手法よりシンプル.
    - 複数のdiscriminatorを必要としない.
    - 複数の損失関数に対して慎重に重み付けする必要がない.
  - 任意のオートエンコーダーに適応可能.
  - 画像やテキストなど多様なドメインに適応可能.
- 異なるドメインで実験を行い, 人間による評価と自動的な評価を行い, ベースラインよりよかった.

## 1. Introduction
提案手法は以下の2つを特徴を持つ
- ランダムシード(しかし属性はあり)からサンプルが生成される.
- ある特定の属性と入力サンプルを与えると, 入力サンプルのその属性を修正することができる.
Contributions
- シンプルかつ普遍性のある方法で条件付き生成を可能にした.
  - (ここでいう普遍性とは, 任意のオートエンコーダーに使えるという意味)
- 複数属性に対して精度のいいdisentanglementを可能にした.
- コードを公開している.

## 2. Related Work
潜在ベクトルから特定の属性情報を分離する問題としてよく用いられる方法は, zの属性を予測するネットワークを用いて, 敵対的学習を行い, 特定の情報を消去し, 所望の属性のみにする方法. この手法の欠点は, 再構成誤差とトレードオフになっており, 学習率のスケーリングが大変であること.

## 3. Method
### 3.1. Problem Formulation
D: データセット
x: 画像 (n次元)
y: 属性 (k次元)

F: オートエンコーダー
G: デコーダー
z: 潜在ベクトル (z = F(x))

K: 置換関数

zの属性がynに変わるように置換した結果をznとすると,
	zn = K(z, yn)
また, zの属性がynに変わるように置換した結果, 生成される画像をxnとすると,
	xn = G(K(z, yn))
結果得られた画像xnの属性はyでなくynであると予測されるようになるが, それ以外の情報は保存されている.

### 3.2. Learning Disentangled Latent Representations via Matrix Subspace Projection
潜在変数zとinvertibleな任意の関数が与えられた時, 
Hはzを新しい線形空間に飛ばしてくれる. (z^=H(z))

どのような線形空間かというと, 以下の(a)と(b)を満たす.
    (a) z^に行列Mをかけることでyに近づけることができる線形空間.
    (b) 直交行列U = [M, N]が存在する.
ただし, NはMの零空間で, Nz^はy以外の情報(s^とする)となる.

要するにHはzからy, zからs^への変換において, ラスト一歩手前まで持っていった感じ.
あとは行列で線形変換すればyとかsになれるよというギリギリのz^まで持っていくのがH.

invertibleなHを省くことで, GとFにHの機能を学習させると考えることができる.
Mに関しては直交行列の一部である必要があるため, GとFにMの機能を学習させることはできない.

Mを最適化するために以下をする必要がある.
- y^をyに近づける.
- s^がz^からの情報を持たないようにするためにs^のノルムを小さくする.

![140_01](https://github.com/wataoka/papersheet2md/blob/main/images/140_01.png?raw=true)

L2に関しては次のように式変形することで計算可能にする.

![140_02](https://github.com/wataoka/papersheet2md/blob/main/images/140_02.png?raw=true)

### 3.4. Conditional Generation and Content Replacement
モデルの学習が完了すると, Mが得られるのでUも得られる. (MN=0をsolverで解けばいい)

なので,

Fを用いてxからz^が得られ,
Uを用いてz^から[y^;s^]が得られる.

そして,

[y^;s^]を[yn;s^]に置き換えて, 
Uの逆行列(Uの転置)を用いてznが得られ,
Gを用いてznからxnが得られる.

## 4. Evaluation
### 4.1. Matrix Subspace Projection in VAE
vanilla VAEに適用した. 
また, 生成画像をシャープにするためにadditional PatchGANを使用した.

baselineは
- Fader networks (Lample+, 2017)
- AttGAN (He+, 2019)

定性的評価として,
Fader netやattGANではメガネに対する編集に失敗し, MSPは成功していることなどを例にあげた.

定量的評価として,
- ResNet-CNNを先に学習させておき, (xn, yn)に対するaccuracyを測定した.
  - MSPが圧勝した.
- Frechet Inception Distance (FID)スコアを算出した.
  - 元画像と生成画像がどれほど似ているかを示す指標.
  - 0がベストで小さければ小さいほど良い.
  - MSPがスコアが高く, 良くなかった. 
    - (他の手法が編集してないことをアピールしたい？)

画像編集において他より秀でていることとして, MSPは40個の属性のうち1個を変更して39個を固定することに長けている. CelabAにおけるdisentangleの世界では, 女性を変更させた時に化粧や口紅をしてはいけないという暗黙のルールがあるが, Fader netなどの方法はそういった変更に適していない.

### 4.2 Human Evaluation of Generated Example Quality
1000枚の画像を抽出し, その画像に対してランダムに1つか2つの属性を編集する.
参加者に対して2枚の画像を見せ, 「クオリティの高い画像を選んでください. もしくはどちらも同じぐらいとしてください.」と質問し, 定性的なクオリティの評価も行った.

比較したのは, オートエンコーダーに対してMSPを入れたか入れていないかにおいて行った.
そして, オートエンコーダーとしてはSeq2seq, VAE, VAE+GANの検証を行った. 

結果としては「MSPを入れた時クオリティが最も悪い」という帰無仮説はp<0.03で棄却された.

### 4.3 Evaluation of Disentanglement
Amazon Mechanical Turkを用いて手動ラベリングを行った.
3つのレベルのリッカート尺度(perfect, recognisable, andunrecognisable/unchanged)で属性変換が成功しているかどうかを参加者に評価してもらった.

結果MSPが最もよかった.

![140_03](https://github.com/wataoka/papersheet2md/blob/main/images/140_03.png?raw=true)

また定量的評価として, ある属性を変更した際, それと相関性のある属性がどれほどclassifierの出力に影響を与えるかを測定した. 例) 男性を変化させた時に, 髭がどれほど動かなかったかを測定している. 結果として, MSPが最も動かなかった. 

所望の属性は最も動き, それと相関性のある属性が最も動かなかったので, MSPが最もdisentangleできていると結論づけている.
