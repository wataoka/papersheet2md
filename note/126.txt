### 概要
最新の画像編集手法です.

![126_01](https://github.com/wataoka/papersheet2md/blob/main/images/126_01.png?raw=true)

これまでの研究では, GANが学習する潜在空間はdistributed representationに従うと仮定してきたが, ベクトル演算現象が観測されてきています. この研究では, GANが学習した潜在意味空間を解釈することで意味論的顔編集を行うための新しいフレームワークInterFaceGANを提案しました. わかりやすく言い直すと, 「潜在空間でうまいことして顔編集したい！」という研究です.

この研究では, 顔生成のためにGANの潜在空間にどのように異なる意味論がエンコードされているかを詳細に研究されています. よく訓練された生成モデルの潜在コードは線形変換後, disentangledされた表現を学習していることが知られています. その表現を利用するために部分空間射影を用いることで, entangledされた(もつれた)意味論を切り離し, 正確な顔属性のコントロールを行います. 性別, 年齢, 表情, メガネの有無などに加えて, GANが誤って生成した画像を修正することも可能となります. また, 顔生成を自然に学習することによって, disentangleされ, コントロールしやすい顔属性表現を獲得することができます.

### Related Work
GAN Inversion (GANの逆変換)
画像空間から潜在変数への逆写像をいるための手法のことをGAN Inversionと言います. [42], [43], [44] (論文中の参照番号をそのまま記載.)

既存手法として, 以下がある.
- インスタンスレベルの最適化手法 [45], [46], [47]
- generatorと対応するencoderの学習 [48], [49], [50]
最近の研究では, 以下がある.
- エンコーダを用いて最適化における良い初期値を見つける. [51], [52]
- Guらは良い再構成のために潜在空間の次元を増やすことを提案している. [53]
- Panらはモデルの重みとともに潜在変数の最適化を試みしている. [54]
- Zhuらはピクセルの値を復元することと共に, 意味論的情報も考慮に入れている. [55]
(論文中の参照番号をそのまま記載.)

### InterFaceGAN
- 与えられているもの
  - 画像
  - 画像に関する属性
  - well-trainedなGANのgenerator
- フレームワーク (というか編集手順)
  - 属性情報を持つ画像をGAN Inversion(上のRelated Work参照)で埋め込む.
  - 属性情報を持つ潜在変数が手に入る.
  - 潜在変数たちを属性aで線形分類する.
  - 潜在空間上での決定境界の超平面が手に入る.
  - ある潜在変数を決定境界の超平面と直交する方向に移動させる.
  - 移動させた潜在変数を生成すると, 属性aに関して編集された画像が手に入る.

以上の手順がInterFaceGANです. お分かりの通り, GANのアーキテクチャなどに関する制約はほとんどなく, 潜在変数から画像を生成できる大きな関数と考えます. そして, 豊かな表現力を持つgeneratorを利用して, その潜在空間上で潜在変数をうまく移動させることで画像編集を行います. 潜在変数を何かしらの属性で線形分類することで得られる決定境界の法線ベクトルをその属性に関する情報のベクトルと考え, 編集に利用していますが, これは豊かな表現力を持つgeneratorが属性情報に関して"いい感じに潜在変数を配置している"という仮定のもと成り立つ方法となります. そして, その手法が最初に示した結果の通り, 大変うまく編集できていますので, その仮定はあながち間違っていないと言えます. ということで, この論文は「潜在変数を移動させることで簡単に編集できます！」ということ単に提案しているだけでなく, 学習済みGANの潜在表現について大きな理解を与えてくれている論文となります. 他にも非常に面白い結果を与えてくれていますので, 一つ一つ見ていきましょう.

### 面白い結果その①「潜在変数は属性の強さ順に並んでいる」
下の画像の左側に"Distance"と書かれていると思います. これは決定境界からの距離を意味しています. 決定境界からの距離が0(決定境界上)である潜在変数を生成すると中段のような画像が得られますが, その潜在変数から決定境界に直交する方向にぶっ飛ばすと, それぞれの属性が以下のようになります.

![126_02](https://github.com/wataoka/papersheet2md/blob/main/images/126_02.png?raw=true)

Poseでは真横を向き, Smileでは爆笑したり,... とにかく面白い結果になったかと思います. このことから潜在変数は潜在空間上で属性の強さ順にある程度は並んでいるのではないかと言えます. (極端な例しか載せていないところから完璧にそうではなさそう？)

### 面白い結果その②「潜在空間には"出来の良さ"という情報もある」
この論文は以下の実験を行いました.
- 画像を適当にサンプル.
- 出来の良い画像と出来の悪い画像を手動でラベリング.
- そのラベル情報を用いて, 先ほどと同じように決定境界を引き, 法線ベクトルを得る.
- そして, 出来の悪い画像に対して, 法線ベクトルの方向に移動させて, 画像を生成.

すると下のように, 画像の出来がよくなります...

![126_03](https://github.com/wataoka/papersheet2md/blob/main/images/126_03.png?raw=true)

「ほんまか？笑」としか思えないような結果ですが, ほんまらしいです. 大変驚きましたが, まぁGANの潜在空間は高次元のだだっ広い空間なので, 綺麗に画像を出力できない場所があってもおかしくはありません. 例えば事前分布において非常に尤度の低い範囲においてはgenerator側が想定できていない値になるので, 必然的に出来は悪くなるでしょう. 何はともあれ, GANの潜在空間には"出来の良さ"という情報もありそうです. (サンプル数が非常に少なく, 確か定量的評価もなかったため, 断言はできない.)

### 面白い結果その③「InterFaceGANは条件付け編集も可能」
筆者はConditional Manipulationと読んでいる手法です.

属性1と属性2があるとします. 今, 属性1に関して編集したくて, 属性2はしっかり固定したいとします. その時に, 属性1と属性2について決定境界を得て, それぞれの法線ベクトル$\bold{n_1}, \bold{n_2}$を得ます. ベクトル$\bold{n_1}$からベクトル$\bold{n_2}$の成分を取り除くと, $\bold{n_1} - (\bold{n_1}^{T}\bold{n_2})\bold{n_2}$となります. このベクトルを用いて編集すると, 属性2の決定境界には平行であり, できるだけ属性1の決定境界を跨ぎやすいベクトルとなっていますので, 属性2を固定しながら属性1を編集できます. 

![126_04](https://github.com/wataoka/papersheet2md/blob/main/images/126_04.png?raw=true)

結果, 以下のようになります. 非常に綺麗に条件付けに成功しているかと思います. ここでは, オリジナル画像から, 年齢を固定, 性別を固定, メガネを編集した時の結果となります.

![126_05](https://github.com/wataoka/papersheet2md/blob/main/images/126_05.png?raw=true)

### wataokaのコメント
Detecting Bias with Generative Counterfactual Face Attribut Augmentationの理論的かつ拡張的な論文で, 面白い結果から面白いGANに対する理解ができる面白い論文.

実はwataokaはこの論文と完全に同じ手法を思いついており, コーディングも進めていた矢先に世に出てきた論文です. Conditional Manipulation, そしてConditional Manipulationの一般化まで完全に同じ式を導出していました. この論文を読んだ時, 血の気が引く思いもしましたが, 同時に自分以上に良い解析であり, 良い書き方であり, 良い論文だなと感服しました. この論文から多くのことを学びました. 隅から隅まで読み込み, 自分にないところを吸収しまくってやりました. そんな僕の研究生活の中で思い出に残るこの論文を第一位にさせていただきました. もちろんそんな私情を差し引いても非常に興味深い結果が多いかと思います.
